{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Toolsmith","text":"<p>Toolsmith transforms regular Python functions into structured tools that can be called by AI models through the OpenAI API. It handles all schema generation and argument deserialization automatically, letting you focus on writing normal Python code.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Simple Integration: Just write regular Python functions with type hints - Toolsmith handles the rest</li> <li>Type Safety: Full type checking and validation using Pydantic</li> <li>Async Support: Built-in support for async functions with parallel execution</li> <li>Pydantic Models: First-class support for complex data structures using Pydantic models</li> <li>Unopinionated: Integrates with any OpenAI API-compatible LLM provider</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Simply define any functions you may have normally:</p> <pre><code>def create_user(name: str, age: int) -&gt; str:\n    \"\"\"Saves a user to the DB\"\"\"\n    return f\"Created user {name}, age {age}\"\n\ndef search_users(query: str, regex: bool) -&gt; str:\n    return \"Found some users\"\n</code></pre> <p>Put it all together and call the OpenAI API:</p> <pre><code>import openai\n\nfrom toolsmith import Toolbox\n\ntoolbox = Toolbox.create([create_user, search_users])\n\nclient = openai.OpenAI()\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Make a 33 year old user called Alice\"}]\n    tools=toolbox.get_schema(),\n)\n\ntool_calls = response.choices[0].message.tool_calls\nresults = toolbox.execute_function_calls(tool_calls)\n</code></pre>"},{"location":"#how-toolboxcreate-works","title":"How Toolbox.create() Works","text":"<p><code>Toolbox.create()</code> is the core function that transforms your Python functions into AI-callable tools. Here's what happens when you call it:</p> <ol> <li> <p>Schema Generation: For each function you provide, Toolsmith makes the function schema available to the model based on its:</p> </li> <li> <p>Function name and docstring (for descriptions)</p> </li> <li> <p>Parameter types (using Python type hints)</p> </li> <li> <p>Type Conversion: Toolsmith converts Python types to JSON Schema:</p> </li> <li> <p>Basic types (str, int, bool) map directly</p> </li> <li>Pydantic models are converted to nested JSON schemas</li> <li>Enums definitions are passed to the model</li> <li> <p>Lists are properly typed based on their item types</p> </li> <li> <p>Validation Setup: Toolsmith creates validators for each function to ensure:</p> </li> <li>All required parameters are provided</li> <li>Parameters match their expected types</li> <li>Complex objects (like Pydantic models) are properly deserialized</li> </ol> <p>When the LLM makes a tool call, Toolsmith handles all the parsing and type conversion, so your function receives properly typed Python objects.</p>"},{"location":"#pydantic-support","title":"Pydantic support","text":"<p>Toolsmith supports Pydantic objects (even nested ones), lists, and enums. For example, if you want to create a list of users:</p> <pre><code>class User(BaseModel):\n    name: str = Field(..., description=\"The name of the user\")\n    age: int = Field(..., description=\"The user's age\")\n\ndef create_users(users: list[User]) -&gt; str:\n    \"\"\"Creates multiple users\"\"\"\n    return f\"Created {len(users)} users!\"\n</code></pre> <p>Any description strings for Pydantic fields will also be made visible to the LLM.</p>"},{"location":"#optional-arguments","title":"Optional arguments","text":"<p>To specify optional arguments, add <code>None</code> as a union type:</p> <pre><code>def create_user(name: str | None) -&gt; str:\n    return \"User created\"\n</code></pre>"},{"location":"#execution","title":"Execution","text":"<p>Toolsmith also makes it easy to execute your functions; it will automatically handle argument deserialization, function execution, and return type formatting so you don't have to.</p>"},{"location":"#pydantic-argument-deserialization","title":"Pydantic argument deserialization","text":"<p>When a function accepts a Pydantic model as an argument, Toolsmith will:</p> <ol> <li>Parse the LLM's JSON response into the correct Pydantic object</li> <li>Validate all fields according to Pydantic's validation rules</li> </ol>"},{"location":"#return-values","title":"Return values","text":"<p>You can return a string or JSON in the form of a serializable <code>dict[str, Any]</code>. If a <code>dict</code> is provided, it will be serialized as JSON.</p>"},{"location":"#returning-function-call-results","title":"Returning function call results","text":"<p>Calling <code>toolbox.execute_function_calls(...)</code> will return results in a format that can be appended as tool message responses. Simply append this as an additional message in the chat message api.</p> <pre><code>tool_calls = response.choices[0].message.tool_calls\nresults = toolbox.execute_function_calls(tool_calls)\nmessages.extend(results)\n</code></pre>"},{"location":"#async-support","title":"Async support","text":"<p>Toolsmith supports <code>async</code> functions out of the box. Simply use <code>AsyncToolbox</code>. If there are multiple tool calls in one response, all calls run in parallel and are returned to the assistant.</p>"},{"location":"#exception-handling","title":"Exception handling","text":"<p>Toolsmith doesn't handle exceptions. Uncaught exceptions in tool handlers will bubble up through the <code>toolbox.execute()</code> calls.</p>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#toolsmith.AsyncToolbox","title":"<code>AsyncToolbox</code>","text":"<p>               Bases: <code>BaseToolbox[Awaitable[Union[str, dict[str, Any]]]]</code></p>"},{"location":"reference/#toolsmith.AsyncToolbox.execute_tool_calls","title":"<code>execute_tool_calls(tool_calls)</code>  <code>async</code>","text":"<p>Execute multiple tool calls asynchronously and returns a result that can be used to respond to the OpenAI API.</p> <p>Parameters:</p> Name Type Description Default <code>tool_calls</code> <code>list[ChatCompletionMessageToolCall]</code> <p>List of tool calls from the OpenAI API to execute</p> required <p>Returns:</p> Type Description <code>list[ChatCompletionToolMessageParam]</code> <p>List of tool messages containing the results of executing each tool call</p> Warning <p>If any individual tool call raises an uncaught exception, other pending tool calls will continue to run but may be left in an indeterminate state. To prevent this, catch exceptions within the tool handler functions themselves and return error messages as part of the normal return value.</p>"},{"location":"reference/#toolsmith.AsyncToolbox.get_func_arg_models","title":"<code>get_func_arg_models()</code>","text":"<p>Get Pydantic models for validating arguments of all functions in the toolbox.</p> <p>Returns:</p> Type Description <code>dict[str, type[BaseModel]]</code> <p>dict[str, type[BaseModel]]: Mapping of function names to their corresponding</p> <code>dict[str, type[BaseModel]]</code> <p>Pydantic models. Each model validates the arguments for that function.</p>"},{"location":"reference/#toolsmith.AsyncToolbox.get_schema","title":"<code>get_schema()</code>","text":"<p>Get OpenAI function schemas for all functions in the toolbox.</p> <p>Returns:</p> Type Description <code>Sequence[ChatCompletionToolParam]</code> <p>Sequence[ChatCompletionToolParam]: List of function schemas compatible with OpenAI's API.</p> <code>Sequence[ChatCompletionToolParam]</code> <p>Each schema describes the name, description and parameters of a function.</p>"},{"location":"reference/#toolsmith.AsyncToolbox.parse_invocations","title":"<code>parse_invocations(tool_calls)</code>","text":"<p>Parse a list of tool calls into a list of Invocation objects. Invocations can be executed by calling the <code>execute</code> method on them, giving you more fine-grained control over execution than the <code>execute_tool_calls</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>tool_calls</code> <code>list[ChatCompletionMessageToolCall]</code> <p>List of tool calls from the OpenAI API to execute</p> required <p>Returns:</p> Type Description <code>list[Invocation[T]]</code> <p>List of Invocation objects, one for each tool call</p>"},{"location":"reference/#toolsmith.Toolbox","title":"<code>Toolbox</code>","text":"<p>               Bases: <code>BaseToolbox[Union[str, dict[str, Any]]]</code></p>"},{"location":"reference/#toolsmith.Toolbox.execute_tool_calls","title":"<code>execute_tool_calls(tool_calls)</code>","text":"<p>Execute tool calls and returns a result that can be used to respond to the OpenAI API. Note that this method is synchronous and will block until all tool calls are executed. For asynchronous execution, use the <code>AsyncToolbox</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>tool_calls</code> <code>list[ChatCompletionMessageToolCall]</code> <p>List of tool calls from the OpenAI API to execute</p> required <p>Returns:</p> Type Description <code>list[ChatCompletionToolMessageParam]</code> <p>List of tool messages containing the results of executing each tool call</p> Warning <p>Tool calls are executed in the order they are given. If a tool call raises an uncaught exception, the remaining tool calls will not be executed. To prevent this, catch exceptions within the tool handler functions themselves and return error messages as part of the normal return value.</p>"},{"location":"reference/#toolsmith.Toolbox.get_func_arg_models","title":"<code>get_func_arg_models()</code>","text":"<p>Get Pydantic models for validating arguments of all functions in the toolbox.</p> <p>Returns:</p> Type Description <code>dict[str, type[BaseModel]]</code> <p>dict[str, type[BaseModel]]: Mapping of function names to their corresponding</p> <code>dict[str, type[BaseModel]]</code> <p>Pydantic models. Each model validates the arguments for that function.</p>"},{"location":"reference/#toolsmith.Toolbox.get_schema","title":"<code>get_schema()</code>","text":"<p>Get OpenAI function schemas for all functions in the toolbox.</p> <p>Returns:</p> Type Description <code>Sequence[ChatCompletionToolParam]</code> <p>Sequence[ChatCompletionToolParam]: List of function schemas compatible with OpenAI's API.</p> <code>Sequence[ChatCompletionToolParam]</code> <p>Each schema describes the name, description and parameters of a function.</p>"},{"location":"reference/#toolsmith.Toolbox.parse_invocations","title":"<code>parse_invocations(tool_calls)</code>","text":"<p>Parse a list of tool calls into a list of Invocation objects. Invocations can be executed by calling the <code>execute</code> method on them, giving you more fine-grained control over execution than the <code>execute_tool_calls</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>tool_calls</code> <code>list[ChatCompletionMessageToolCall]</code> <p>List of tool calls from the OpenAI API to execute</p> required <p>Returns:</p> Type Description <code>list[Invocation[T]]</code> <p>List of Invocation objects, one for each tool call</p>"},{"location":"reference/#toolsmith.func_to_pydantic","title":"<code>func_to_pydantic(func)</code>","text":"<p>Convert a function's arguments to a Pydantic model. Used for input validation.</p>"},{"location":"reference/#toolsmith.func_to_schema","title":"<code>func_to_schema(fn)</code>","text":"<p>Wraps a Python function to be compatible with OpenAI's function calling API.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The Python function to wrap</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>ChatCompletionToolParam</code> <p>Function schema compatible with OpenAI's API</p>"}]}